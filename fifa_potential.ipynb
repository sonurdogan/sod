{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession.builder.appName('rating_potential').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+\n",
      "|Age|Overall|Potential|\n",
      "+---+-------+---------+\n",
      "| 31|     94|       94|\n",
      "| 33|     94|       94|\n",
      "| 26|     92|       93|\n",
      "| 27|     91|       93|\n",
      "| 27|     91|       92|\n",
      "+---+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('data.csv',header=True , inferSchema=True)\n",
    "data.select(\"Age\",\"Overall\",\"Potential\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF,testDF=data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vektör=VectorAssembler(inputCols=[\"Age\",\"Overall\"]\n",
    "                       ,outputCol=\"features\")\n",
    "vektörtrain=vektör.transform(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression(featuresCol=\"features\",labelCol=\"Potential\",maxIter=10, regParam=0.5,elasticNetParam=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel=lr.fit(vektörtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features= -0.712136075614766 *Age + 0.7328735874848807 *Overall + 40.639620188224946\n"
     ]
    }
   ],
   "source": [
    "c_1=lrmodel.coefficients[0]\n",
    "c_2=lrmodel.coefficients[1]\n",
    "b=lrmodel.intercept\n",
    "print(\"Features=\",c_1,\"*Age\",\"+\",c_2,\"*Overall\",\"+\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+---------+-----------------+\n",
      "|Age|Overall|   features|Potential|       prediction|\n",
      "+---+-------+-----------+---------+-----------------+\n",
      "| 33|     94|[33.0,94.0]|       94|86.02924691651646|\n",
      "| 27|     91|[27.0,91.0]|       91|88.10344260775041|\n",
      "| 32|     91|[32.0,91.0]|       91|84.54276222967658|\n",
      "| 27|     89|[27.0,89.0]|       90|86.63769543278065|\n",
      "| 24|     89|[24.0,89.0]|       94|88.77410365962496|\n",
      "| 33|     89|[33.0,89.0]|       89|82.36487897909205|\n",
      "| 19|     88|[19.0,88.0]|       95| 91.6019104502139|\n",
      "| 26|     88|[26.0,88.0]|       90|86.61695792091054|\n",
      "| 26|     88|[26.0,88.0]|       91|86.61695792091054|\n",
      "| 27|     87|[27.0,87.0]|       90| 85.1719482578109|\n",
      "+---+-------+-----------+---------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline=Pipeline(stages=[vektör,lr])\n",
    "pipelinemodel=pipeline.fit(trainDF)\n",
    "sonuc=pipelinemodel.transform(testDF)\n",
    "sonuc.select(\"Age\",\"Overall\",\"features\",\"Potential\",\"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE): 2.793463044656607\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Potential\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(sonuc)\n",
    "print (\"Root Mean Square Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data =  0.7995829036765745\n"
     ]
    }
   ],
   "source": [
    "lr_evaluator = RegressionEvaluator(labelCol=\"Potential\",predictionCol=\"prediction\",metricName=\"r2\")\n",
    "r2=lr_evaluator.evaluate(sonuc)\n",
    "print(\"R Squared (R2) on test data = \",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
